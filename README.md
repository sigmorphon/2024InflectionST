# Data-efficient Morphological Inflection

This year we will focus on data efficiency and active learning. We will provide a pool of samples available for training and systems would require to get as high accuracy as possible by choosing subsamples of fixed size (e.g., 100, 500, 1000, 2000). The accuracy will be evaluated on the test (unseen) samples.

For each language we will focus on one class only (nouns, verbs, or adjectives).

By doing that, we will target the following research questions:

I. What is the minimum number of samples that is required to achieve a particular accuracy level in each language? Does it correlate with morphological complexity? Further reading on the topic:  1) [Morphological Organization: The Low Conditional Entropy Conjecture](https://muse.jhu.edu/article/521667/summary); 2) Cotterell, Kirov, Hulden, Eisner https://aclanthology.org/Q19-1021.pdf; 3) Çöltekin and Rama https://www.degruyter.com/document/doi/10.1515/lingvan-2021-0007/html?lang=en

II. What is the best strategy to sample selection? Further reading: 1) Muradoglu and Hulden https://aclanthology.org/2022.emnlp-main.492.pdf; 2) Goldman and Tsarfaty https://aclanthology.org/2021.emnlp-main.159.pdf

III. What are the most essential paradigm parts (principal parts of the paradigm)? How do we learn them automatically? Will the samples selected by systems resemble the principal parts? Further reading on the topic: 1) Finkel & Stump https://link.springer.com/article/10.1007/s11525-007-9115-9 ; 2) Cotterell, Glassman, Kirov https://aclanthology.org/E17-2120.pdf 

IV. How well do the systems learn syncretic forms? Further reading: Muradoglu, Evans, Vylomova: https://aclanthology.org/2020.alta-1.5.pdf

# Languages
The experiments will be conducted for the following languages: Mongolian, Kazakh, Turkish, Central Kurdish, Arabic, Polish, Sanskrit, Pitjantjatjara, Central Pame, Walmajarri



