# Data-efficient Morphological Inflection

This year we will focus on data efficiency and active learning. We will provide a pool of samples available for training and systems would require to get as high accuracy as possible by choosing subsamples of fixed size (e.g., 100, 500, 1000, 2000). The accuracy will be evaluated on the test (unseen) samples.

For each language we will focus on one class only (nouns, verbs, or adjectives).

By doing that, we will target the following research questions:
  1) What is the minimum number of samples that is required to achieve a particular accuracy level on each language?
  2)  What is the best strategy to choose samples?
  3)  Are the most essential paradigm parts?
  4)  How well do the systems learn syncretic forms?


The experiments will be conducted for the following languages:
  --  Mongolian
  --  Kazakh
  --  Turkish
   --  Central Kurdish
   --  Hebrew
   --  Russian
   --  Sanskrit
   --  Pitjantjatjara



